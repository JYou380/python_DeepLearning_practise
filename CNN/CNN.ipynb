{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kagglecatsanddogs_5340/PetImages/Cat image loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kagglecatsanddogs_5340/PetImages/Dog image loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "images = [] \n",
    "labels = []\n",
    "\n",
    "dict_labels={\"Cat\":0 , \"Dog\":1}\n",
    "size = (40,40)\n",
    "\n",
    "for folders in glob.glob(\"./kagglecatsanddogs_5340/PetImages/*\"):\n",
    "    print (folders,\"image loading\")\n",
    "    for filename in os.listdir(folders):\n",
    "        label=folders.split(\"/\")[-1]\n",
    "        #print (label)\n",
    "        try:\n",
    "            img=cv2.imread(os.path.join(folders,filename))\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img,dsize=size)\n",
    "                images.append(img)\n",
    "                labels.append(dict_labels[label])\n",
    "        except:\n",
    "            print (os.path.join(folders,filename),\"can't load\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946 24946\n"
     ]
    }
   ],
   "source": [
    "print (len(images),len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_feature,test_feature,train_label,test_label = train_test_split(images,labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_feature = np.array(train_feature)\n",
    "test_feature = np.array(test_feature)\n",
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956 4990\n",
      "(19956, 40, 40, 3) (19956,)\n",
      "(4990, 40, 40, 3) (4990,)\n"
     ]
    }
   ],
   "source": [
    "print (len(train_feature),len(test_feature))\n",
    "print (train_feature.shape,train_label.shape)\n",
    "print (test_feature.shape,test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesavepath=\"Cat_Dog_Dataset/\"\n",
    "if not os.path.exists(imagesavepath):\n",
    "    os.mkdir(imagesavepath)\n",
    "\n",
    "np.save(imagesavepath+\"train_feature.npy\",train_feature)\n",
    "np.save(imagesavepath+\"test_feature.npy\",test_feature)\n",
    "np.save(imagesavepath+\"train_label.npy\",train_label)\n",
    "np.save(imagesavepath+\"test_label.npy\",test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_vector = train_feature.reshape(len(train_feature),40,40,3).astype('float32')\n",
    "test_feature_vector = test_feature.reshape(len(test_feature),40,40,3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_normalize = train_feature_vector/255\n",
    "test_feature_normalize = test_feature_vector/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "\n",
    "train_label_onehot = to_categorical(train_label)\n",
    "test_label_onehot = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=10,kernel_size=(5,5),padding='same',input_shape=(40,40,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=20,kernel_size=(5,5),padding='same',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 40, 40, 10)        760       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 20, 20, 10)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 20, 10)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 20)        5020      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 20)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 20)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1024512   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1031318 (3.93 MB)\n",
      "Trainable params: 1031318 (3.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 - 26s - loss: 0.7051 - accuracy: 0.5586 - val_loss: 0.6833 - val_accuracy: 0.5616 - 26s/epoch - 328ms/step\n",
      "Epoch 2/10\n",
      "80/80 - 23s - loss: 0.6478 - accuracy: 0.6240 - val_loss: 0.6523 - val_accuracy: 0.6075 - 23s/epoch - 292ms/step\n",
      "Epoch 3/10\n",
      "80/80 - 24s - loss: 0.6051 - accuracy: 0.6685 - val_loss: 0.5906 - val_accuracy: 0.6759 - 24s/epoch - 296ms/step\n",
      "Epoch 4/10\n",
      "80/80 - 23s - loss: 0.5711 - accuracy: 0.6984 - val_loss: 0.5719 - val_accuracy: 0.7039 - 23s/epoch - 290ms/step\n",
      "Epoch 5/10\n",
      "80/80 - 23s - loss: 0.5462 - accuracy: 0.7185 - val_loss: 0.5447 - val_accuracy: 0.7229 - 23s/epoch - 282ms/step\n",
      "Epoch 6/10\n",
      "80/80 - 22s - loss: 0.5188 - accuracy: 0.7425 - val_loss: 0.5762 - val_accuracy: 0.6994 - 22s/epoch - 279ms/step\n",
      "Epoch 7/10\n",
      "80/80 - 22s - loss: 0.5011 - accuracy: 0.7551 - val_loss: 0.5272 - val_accuracy: 0.7255 - 22s/epoch - 277ms/step\n",
      "Epoch 8/10\n",
      "80/80 - 23s - loss: 0.4756 - accuracy: 0.7711 - val_loss: 0.5139 - val_accuracy: 0.7442 - 23s/epoch - 286ms/step\n",
      "Epoch 9/10\n",
      "80/80 - 22s - loss: 0.4477 - accuracy: 0.7873 - val_loss: 0.5165 - val_accuracy: 0.7487 - 22s/epoch - 280ms/step\n",
      "Epoch 10/10\n",
      "80/80 - 25s - loss: 0.4186 - accuracy: 0.8079 - val_loss: 0.5030 - val_accuracy: 0.7588 - 25s/epoch - 307ms/step\n"
     ]
    }
   ],
   "source": [
    "train_history= model.fit(x=train_feature_normalize,y=train_label_onehot,validation_split=0.2,epochs=10,batch_size=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 2s 15ms/step - loss: 0.4938 - accuracy: 0.7659\n",
      "scores =  0.7659318447113037\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_feature_normalize,test_label_onehot)\n",
    "print (\"scores = \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 4s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_feature_normalize)\n",
    "prediction = np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 1 1 1 0] [1 1 0 1 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (test_label[0:10],prediction[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ojy/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('cat_dog_CNN_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
